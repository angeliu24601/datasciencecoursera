# 1. Load the Alzheimer's disease data using the commands:
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
# 1. Load the Alzheimer's disease data using the commands:
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
## Which of the following commands will create non-overlapping training and
## test sets with about 50% of the observations assigned to each?
adData <- data.frame(diagnosis, predictors)
View(adData)
?adData
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
?CreateDataPartition
# 1. Load the Alzheimer's disease data using the commands:
library(AppliedPredictiveModeling)
library(caret)
install.packages("caret")
library(caret)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
View(training)
View(testing)
View(adData)
?createDataPartition
adDate <- data.frame(diagnosis)
View(adDate)
count(adDate)
count(adDate, diagnosis)
trainIndex = createDataPartition(diagnosis,p=0.5)
training = adData[trainIndex,]
trainIndex = createDataPartition(diagnosis,p=0.5)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
trainIndex = createDataPartition(diagnosis,p=0.5, list = FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(caret);library(tidyverse)
rm(list=ls())
# 2. Load the cement data using the commands:
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(mixtures)
View(mixtures)
View(testing)
View(training)
library(Hmisc)
install.packages("Hmisc")
?cut2
library(Hmisc)
?cut2
head(createDataPartition(mixtures$CompressiveStrength, p = 3/4))
head(createDataPartition(mixtures$CompressiveStrength, p = 3/4)[1])
library(ggplot2)
?plotmatrix
# Make a plot of the outcome (CompressiveStrength) versus the index of the samples.
# Color by each of the variables in the data set (you may find the cut2() function
# in the Hmisc package useful for turning continuous covariates into factors).
# What do you notice in these plots?
library(GGally)
t <- ggplot(data = training, aes(x = inTrain, y = CompressiveStrength))+
geom_point()
t
index <- seq_along(training)
index <- seq_along(nrow(training))
index <- 1:nrow(training)
t <- ggplot(data = training, aes(x = index, y = CompressiveStrength)) +
geom_point()
t
s <- ggpairs(training)
s
cutCS <- cut2(training$CompressiveStrength, g = 4)
t <- ggplot(data = training, aes(x = index, y = cutCS)) +
geom_point()
t
# 2. Load the cement data using the commands:
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
View(training)
training2 <- training %>%
gather(key = VAR, value = VAL, -CompressiveStrength)
View(training2)
training2 <- training %>%
rowid_to_column() %>%
gather(key = VAR, value = VAL, -CompressiveStrength, -rowid)
ggplot(data = training2, aes(x = rowid, y = CompressiveStrength, color = VAL))+
geom_point()
ggplot(data = training2, aes(x = rowid, y = CompressiveStrength, color = VAR))+
geom_point()
training2 <- training %>%
rowid_to_column() %>%
mutate(cutCS = cut2(CompressiveStrength, g = 4)) %>%
gather(key = VAR, value = VAL, -CompressiveStrength, -rowid)
ggplot(data = training2, aes(x = rowid, y = CompressiveStrength, color = VAR))+
geom_point()
ggplot(data = training2, aes(y = rowid, x = CompressiveStrength, color = VAR))+
geom_point()
ggplot(data = training2, aes(y = rowid, x = CompressiveStrength, color = VAR))+
geom_boxplot()
rm(list=ls())
# 3. Load the cement data using the commands:
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
# Make a histogram and confirm the SuperPlasticizer variable is skewed.
# Normally you might use the log transform to try to make the data more symmetric.
# Why would that be a poor choice for this variable?
ggplot(data = training, aes(x = SuperPlasticizer)) +
geom_histogram()
colnames(training)
# Make a histogram and confirm the SuperPlasticizer variable is skewed.
# Normally you might use the log transform to try to make the data more symmetric.
# Why would that be a poor choice for this variable?
ggplot(data = training, aes(x = Superplasticizer)) +
geom_histogram()
rm(list=ls())
# 4. Load the Alzheimer's disease data using the commands:
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
training = adData[ inTrain,]
testing = adData[-inTrain,]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
# Find all the predictor variables in the training set that begin with IL.
# Perform principal components on these variables with the preProcess() function
# from the caret package. Calculate the number of principal components needed to
# capture 80% of the variance. How many are there?
IL <- select(training, starts_wit("IL"))
# Find all the predictor variables in the training set that begin with IL.
# Perform principal components on these variables with the preProcess() function
# from the caret package. Calculate the number of principal components needed to
# capture 80% of the variance. How many are there?
IL <- select(training, starts_with("IL"))
# Find all the predictor variables in the training set that begin with IL.
# Perform principal components on these variables with the preProcess() function
# from the caret package. Calculate the number of principal components needed to
# capture 80% of the variance. How many are there?
IL <- grep("^IL", colnames(training))
preProc <- preProcess(training[, IL], method = "pca", thresh = 0.8)
preProc$rotation
rm(list=ls())
# 5. Load the Alzheimer's disease dat using the commands:
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
fit1 <- train(diagnosis ~ ., method = "glm", data = training)
library("e1071")
library(e1071)
install.packages("e1071")
library(e1071)
fit1 <- train(diagnosis ~ ., method = "glm", data = training)
# Create a training data set consisting of only the predictors with variable
# names beginning with IL and the diagnosis. Build two predictive models,
# one using the predictors as they are and one using PCA with
# principal components explaining 80% of the variance in the predictors.
# Use method="glm" in the train function.
#
# What is the accuracy of each method in the test set? Which is more accurate?
data_il <- select(training, starts_with("IL"))
fit1 <- train(diagnosis ~ ., method = "glm", data = data_il)
# Create a training data set consisting of only the predictors with variable
# names beginning with IL and the diagnosis. Build two predictive models,
# one using the predictors as they are and one using PCA with
# principal components explaining 80% of the variance in the predictors.
# Use method="glm" in the train function.
#
# What is the accuracy of each method in the test set? Which is more accurate?
data_il <- select(training, starts_with("IL"), diagnosis)
fit1 <- train(diagnosis ~ ., method = "glm", data = data_il)
prediction1 <- predict(fit1, newdata = testing)
confusionMatrix(prediction1, testing$diagnosis)
fit2 <- train(data_il$diagnosis ~ ., method = "glm", preProcess = "pca",
data = data_il)
fit2 <- train(data_il$diagnosis ~ ., method = "glm", preProcess = "pca",
data = data_il, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
?train
fit2 <- train(diagnosis ~ ., method = "glm", preProcess = "pca",
data = data_il, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
prediction2 <- predict(fit2, newdata = testing)
confusionMatrix(prediction2, testing$diagnosis)
rm(list=ls())
# 1. Load the Alzheimer's disease data using the commands:
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
# Which of the following commands will create non-overlapping training and
# test sets with about 50% of the observations assigned to each?
adData = data.frame(diagnosis, predictors)
trainIndex = createDataPartition(diagnosis,p=0.5, list = FALSE)
# 4. Load the Alzheimer's disease data using the commands:
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
# Find all the predictor variables in the training set that begin with IL.
# Perform principal components on these variables with the preProcess() function
# from the caret package. Calculate the number of principal components needed to
# capture 80% of the variance. How many are there?
IL <- grep("^IL", colnames(training))
preProc <- preProcess(training[, IL], method = "pca", thresh = 0.9)
preProc$rotation
