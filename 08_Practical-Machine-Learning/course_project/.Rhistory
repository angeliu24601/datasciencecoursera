### to build the model
var_model <- ref.colnames %>%
filter(str_detect(COLNAME, "X|user_name|timestamp|window"))
### excluding the columns that are all NA and the non-measurement columns
### such as username, timestamp etc. we will end up using the following variables
### to build the model
var_model <- ref.colnames %>%
filter(ALL_NA == FALSE, !str_detect(COLNAME, "X|user_name|timestamp|window"))
View(training)
### excluding the columns that are
### - the outcome variable (class)
### - all NA
### - non-measurement columns, such as username, timestamp etc.
### we will end up using the following variables to build the model
var_model <- ref.colnames %>%
filter(ALL_NA == FALSE,
!str_detect(COLNAME, "classe|X|user_name|timestamp|window"))
var_model$COLNAME
### excluding the columns that are
### - the outcome variable (class)
### - all NA
### - non-measurement columns, such as username, timestamp etc.
### we will end up using the following variables to build the model
var_model <- ref.colnames %>%
filter(ALL_NA == FALSE,
!str_detect(COLNAME, "classe|X|user_name|timestamp|window")) %>%
pull(COLNAME)
## models ----------------------------------------------------------------------
### random forest
model_rf <- train(
classe ~ .,
data=training[, c("classe", var_model)],
trControl=fitControl,
method='rf',
ntree=100
)
## set up ----------------------------------------------------------------------
## load required packages
library(tidyverse);library(caret)
## models ----------------------------------------------------------------------
### random forest
model_rf <- train(
classe ~ .,
data=training[, c("classe", var_model)],
trControl=fitControl,
method='rf',
ntree=100
)
training[, c("classe", var_model)]
## models ----------------------------------------------------------------------
### random forest
model_rf <- train(
classe ~ .,
data = training[, c("classe", var_model)],
method = 'rf',
ntree = 100
)
View(training)
View(ref.colnames)
### excluding the columns that are
### - the outcome variable (class)
### - all NA
### - non-measurement columns, such as username, timestamp etc.
### we will end up using the following variables to build the model
var_model <- ref.colnames %>%
filter(N_NA == 0,
!str_detect(COLNAME, "classe|X|user_name|timestamp|window")) %>%
pull(COLNAME)
## models ----------------------------------------------------------------------
### random forest
model_rf <- train(
classe ~ .,
data = training[, c("classe", var_model)],
method = 'rf',
ntree = 100
)
saveRDS(model_rf, "./model/model_rf.rds")
prediction <- predict(model_rf, newdata = test)
prediction
View(prediction)
## set up ----------------------------------------------------------------------
## load required packages
library(tidyverse);library(caret)
## download data
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
"./data/pml-training.csv")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
"./data/pml-testing.csv")
## load required packages
library(tidyverse)
## load data -------------------------------------------------------------------
training <- read.csv("./data/pml-training.csv", stringsAsFactors = FALSE,
## attn: several different NA strings
na.strings = c("", "#DIV/0!", NA_character_))
test <- read.csv("./data/pml-testing.csv", stringsAsFactors = FALSE,
## attn: several different NA strings
na.strings = c("", "#DIV/0!", NA_character_))
## exlpore and clean up if necessary -------------------------------------------
ref.colnames <- tibble(
COLNAME = colnames(training),
CLASS = map_chr(training, class) %>% unname(),
N_NA = map_int(training, ~ is.na(.x) %>% sum())) %>%
mutate(ALL_NA = ifelse(N_NA == nrow(training), TRUE, FALSE))
### excluding the columns that are
### - the outcome variable (class)
### - mostly NAs
### - non-measurement columns, such as username, timestamp etc.
### we will end up using the following variables to build the model
var_model <- ref.colnames %>%
filter(N_NA == 0,
!str_detect(COLNAME, "classe|X|user_name|timestamp|window")) %>%
pull(COLNAME)
rm(list=ls())
## models ----------------------------------------------------------------------
### split the training data and keep part for cross-validation
training <- createDataPartition(y = training, p = 0.75, list = FALSE)
## models ----------------------------------------------------------------------
### split the training data and keep part for cross-validation
training <- createDataPartition(y = Classe, p = 0.75, list = FALSE)
## set up ----------------------------------------------------------------------
## load required packages
library(tidyverse);library(caret)
## download data
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
"./data/pml-training.csv")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
"./data/pml-testing.csv")
## load required packages
library(tidyverse)
## load data -------------------------------------------------------------------
training <- read.csv("./data/pml-training.csv", stringsAsFactors = FALSE,
## attn: several different NA strings
na.strings = c("", "#DIV/0!", NA_character_))
## exlpore and clean up if necessary -------------------------------------------
ref.colnames <- tibble(
COLNAME = colnames(training),
CLASS = map_chr(training, class) %>% unname(),
N_NA = map_int(training, ~ is.na(.x) %>% sum())) %>%
mutate(ALL_NA = ifelse(N_NA == nrow(training), TRUE, FALSE))
### excluding the columns that are
### - the outcome variable (class)
### - mostly NAs
### - non-measurement columns, such as username, timestamp etc.
### we will end up using the following variables to build the model
var_model <- ref.colnames %>%
filter(N_NA == 0,
!str_detect(COLNAME, "classe|X|user_name|timestamp|window")) %>%
pull(COLNAME)
createDataPartition()
?createDataPartition()
## models ----------------------------------------------------------------------
### split the training data and keep part for cross-validation
training <- createDataPartition(y = Classe, p = 0.75, list = FALSE)
## models ----------------------------------------------------------------------
### split the training data and keep part for cross-validation
training <- createDataPartition(y = classe, p = 0.75, list = FALSE)
View(ref.colnames)
## models ----------------------------------------------------------------------
### split the training data and keep part for cross-validation
training <- createDataPartition(y = training$classe, p = 0.75, list = FALSE)
## load data -------------------------------------------------------------------
training <- read.csv("./data/pml-training.csv", stringsAsFactors = FALSE,
## attn: several different NA strings
na.strings = c("", "#DIV/0!", NA_character_))
## exlpore and clean up if necessary -------------------------------------------
ref.colnames <- tibble(
COLNAME = colnames(training),
CLASS = map_chr(training, class) %>% unname(),
N_NA = map_int(training, ~ is.na(.x) %>% sum())) %>%
mutate(ALL_NA = ifelse(N_NA == nrow(training), TRUE, FALSE))
### excluding the columns that are
### - the outcome variable (class)
### - mostly NAs
### - non-measurement columns, such as username, timestamp etc.
### we will end up using the following variables to build the model
var_model <- ref.colnames %>%
filter(N_NA == 0,
!str_detect(COLNAME, "classe|X|user_name|timestamp|window")) %>%
pull(COLNAME)
## models ----------------------------------------------------------------------
### split the training data and keep part for cross-validation
inTrain <- createDataPartition(y = training$classe, p = 0.75, list = FALSE)
source('~/Downloads/OneDrive - Inter-American Development Bank Group/ForMe/Coursera_DataScience/08_Practical-Machine-Learning/course_project/R/eda.R', echo=TRUE)
training <- train[inTrain,]
## models ----------------------------------------------------------------------
### split the training data and keep part for cross-validation
inTrain <- createDataPartition(y = training$classe, p = 0.7, list = FALSE)
training <- train[inTrain,]
training <- training[inTrain, ]
testing <- training[-inTrain, ]
### random forest
model_rf <- train(
classe ~ .,
data = training[, c("classe", var_model)],
method = "rf",
ntree = 100
)
### decision trees with CART (rpart)
model_rpart <- train(
classe ~ .,
data = training[, c("classe", var_model)],
method = "rpart"
)
saveRDS(model_rpart, "./model/model_rpart.rds")
saveRDS(model_gbm, "./model/model_gbm.rds")
### gbm
model_gbm <- train(
classe ~ .,
data = training[, c("classe", var_model)],
method = "gbm"
)
saveRDS(model_gbm, "./model/model_gbm.rds")
model_rf <- readRDS("./model/model_rf.rds")
## load required packages
library(tidyverse)
## load data -------------------------------------------------------------------
training <- read.csv("./data/pml-training.csv", stringsAsFactors = FALSE,
## attn: several different NA strings
na.strings = c("", "#DIV/0!", NA_character_))
## exlpore and clean up if necessary -------------------------------------------
ref.colnames <- tibble(
COLNAME = colnames(training),
CLASS = map_chr(training, class) %>% unname(),
N_NA = map_int(training, ~ is.na(.x) %>% sum())) %>%
mutate(ALL_NA = ifelse(N_NA == nrow(training), TRUE, FALSE))
### excluding the columns that are
### - the outcome variable (class)
### - mostly NAs
### - non-measurement columns, such as username, timestamp etc.
### we will end up using the following variables to build the model
var_model <- ref.colnames %>%
filter(N_NA == 0,
!str_detect(COLNAME, "classe|X|user_name|timestamp|window")) %>%
pull(COLNAME)
## cross-validation
model_rpart <-  readRDS("./model/model_rpart.rds")
model_gbm <- readRDS("./model/model_gbm.rds")
## load required packages
library(tidyverse);library(caret)
install.packages("caret")
## cross-validation
model_rpart <-  readRDS("./model/model_rpart.rds")
model_gbm <- readRDS("./model/model_gbm.rds")
model_rf <- readRDS("./model/model_rf.rds")
## models ----------------------------------------------------------------------
### split the training data and keep part for cross-validation
inTrain <- createDataPartition(y = training$classe, p = 0.7, list = FALSE)
training <- training[inTrain, ]
testing <- training[-inTrain, ]
## load data -------------------------------------------------------------------
training <- read.csv("./data/pml-training.csv", stringsAsFactors = FALSE,
## attn: several different NA strings
na.strings = c("", "#DIV/0!", NA_character_))
### excluding the columns that are
### - the outcome variable (class)
### - mostly NAs
### - non-measurement columns, such as username, timestamp etc.
### we will end up using the following variables to build the model
var_model <- ref.colnames %>%
filter(N_NA == 0,
!str_detect(COLNAME, "classe|X|user_name|timestamp|window")) %>%
pull(COLNAME)
## models ----------------------------------------------------------------------
### split the training data and keep part for cross-validation
inTrain <- createDataPartition(y = training$classe, p = 0.7, list = FALSE)
## load required packages
library(tidyverse);library(caret)
## models ----------------------------------------------------------------------
### split the training data and keep part for cross-validation
inTrain <- createDataPartition(y = training$classe, p = 0.7, list = FALSE)
training <- training[inTrain, ]
testing <- training[-inTrain, ]
test_rpart <- predict(model_rpart, newdata = testing)
test_gbm <- predict(model_gbm, newdata = testing)
install.packages("gbm")
test_gbm <- predict(model_gbm, newdata = testing)
test_rf <- predict(model_rf, newdata = testing)
install.packages("randomForest")
test_rf <- predict(model_rf, newdata = testing)
accuracy_rpart <- confusionMatrix(test_rpart, testing$classe)
accuracy_gbm <- confusionMatrix(test_gbm, testing$classe)
accuracy_rf <- confusionMatrix(test_rf, testing$classe)
?confusionMatrix
accuracy_rpart <- confusionMatrix(data = test_rpart, reference = testing$classe)
class(testing$classe)
accuracy_rpart <- confusionMatrix(data = test_rpart, reference = factor(testing$classe))
install.packages("e1071")
accuracy_rpart <- confusionMatrix(data = test_rpart, reference = factor(testing$classe))
accuracy_gbm <- confusionMatrix(test_gbm, factor(testing$classe))
accuracy_rf <- confusionMatrix(test_rf, factor(testing$classe))
accuracy_rpart
accuracy_rpart$overall
accuracy <- tibble(rpart = accuracy_rpart$overall$Accuracy)
accuracy <- tibble(rpart = accuracy_rpart$overall["Accuracy"])
View(accuracy)
accuracy <- tibble(rpart = accuracy_rpart$overall["Accuracy"],
gbm = accuracy_gbm$overall["Accuracy"],
rf = accuracy_rf$overall["Accuracy"])
accuracy <- data.frame(rpart = accuracy_rpart$overall["Accuracy"],
gbm = accuracy_gbm$overall["Accuracy"],
rf = accuracy_rf$overall["Accuracy"])
accuracy_rf$overall["Accuracy"]
accuracy_rf$overall["Accuracy"]*1000
knitr::opts_chunk$set(echo = TRUE)
getwd()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
"./data/pml-training.csv")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
"./data/pml-testing.csv")
training <- read.csv("./data/pml-training.csv", stringsAsFactors = FALSE,
## attn: several different NA strings
na.strings = c("", "#DIV/0!", NA_character_))
glipmse(training)
glipms(training)
library(tidyverse);library(caret)
glipmse(training)
glipmse(training)
glipms(training)
?glimpse
glimps(training)
glimpse(training)
## create a dataframe and store the characteristics of the variables
ref.columns <- data.frame(
COLNAME = colnames(training),
CLASS = map_chr(training, class) %>% unname(),
N_NA = map_int(training, ~ is.na(.x) %>% sum())) %>%
mutate(ALL_NA = ifelse(N_NA == nrow(training), TRUE, FALSE))
View(ref.columns)
## column names
COLNAME = colnames(training),
## create a dataframe and store the characteristics of the variables
ref.columns <- data.frame(
## column names
COLNAME = colnames(training),
## column class
CLASS = map_chr(training, class) %>% unname(),
## how many NAs in each column
N_NA = map_int(training, ~ is.na(.x) %>% sum())) %>%
## what is the percentage of NAs for each column
mutate(PERCENT_NA = N_NA / nrow(training))
## print the
kable(ref.columns)
library(tidyverse);library(caret);library(knitr)
## print the
kable(ref.columns)
ncols(training)
ncol(training)
library(tidyverse);library(caret);library(knitr);library(DT)
install.packages("DT")
library(tidyverse);library(caret);library(knitr);library(DT)
## print the table nicely
datatable(ref.columns)
## print the table nicely
datatable(ref.columns, filter = "top")
library(tidyverse);library(caret);library(knitr);library(DT);library(scales)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse);library(caret);library(knitr);library(DT);library(scales)
## column names
COLNAME = colnames(training),
## create a dataframe and store the characteristics of the variables
ref.columns <- data.frame(
## column names
COLNAME = colnames(training),
## column class
CLASS = map_chr(training, class) %>% unname(),
## how many NAs in each column
N_NA = map_int(training, ~ is.na(.x) %>% sum())) %>%
## what is the percentage of NAs for each column
mutate(PERCENT_NA = percent(N_NA / nrow(training)))
## print the table nicely
datatable(ref.columns, filter = "top")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse);library(caret);library(knitr);library(DT)
## column names
COLNAME = colnames(training),
## create a dataframe and store the characteristics of the variables
ref.columns <- data.frame(
## column names
COLNAME = colnames(training),
## column class
CLASS = map_chr(training, class) %>% unname(),
## how many NAs in each column
N_NA = map_int(training, ~ is.na(.x) %>% sum())) %>%
## what is the percentage of NAs for each column
mutate(PERCENT_NA = round(N_NA / nrow(training), 3))
## print the table nicely
datatable(ref.columns, filter = "top")
## print the table nicely
datatable(ref.columns, filter = "top")
ref.columns %>%
filter(PERCENT_NA < 0.9) %>%
pull(COLNAME)
ref.columns %>%
filter(PERCENT_NA < 0.9, CLASS != "character") %>%
pull(COLNAME)
ref.columns %>%
filter(PERCENT_NA < 0.9, CLASS != "character") %>%
pull(COLNAME)
View(training)
?data.frame
## create a dataframe and store the characteristics of the variables
ref.columns <- tibble(
## column names
COLNAME = colnames(training),
## column class
CLASS = map_chr(training, class) %>% unname(),
## how many NAs in each column
N_NA = map_int(training, ~ is.na(.x) %>% sum())) %>%
## what is the percentage of NAs for each column
mutate(PERCENT_NA = round(N_NA / nrow(training), 3))
## print the table nicely
datatable(ref.columns, filter = "top")
ref.columns %>%
filter(PERCENT_NA < 0.9, CLASS != "character", COLNAME != "X") %>%
pull(COLNAME)
ref.columns %>%
filter(PERCENT_NA < 0.9,
!str_detect(COLNAME, "X|user_name|timestamp|window")) %>%
pull(COLNAME)
?trainControl
## prediction ------------------------------------------------------------------
testing_predict <- read.csv("./data/pml-testing.csv", stringsAsFactors = FALSE,
## attn: several different NA strings
na.strings = c("", "#DIV/0!", NA_character_))
colnames(testing_predict)
set.seed(202)
InTrain <- createDataPartition(y = training$classe, p = 0.7, list = FALSE)
part_train <- training[InTrain,]
part_test <- training[-InTrain,]
InCols <- ref.columns %>%
filter(PERCENT_NA < 0.9,
!str_detect(COLNAME, "X|user_name|timestamp|window")) %>%
pull(COLNAME) %>%
print()
part_train <- training[InTrain, InCols]
set.seed(202)
InTrain <- createDataPartition(y = training$classe, p = 0.75, list = FALSE)
part_train <- training[InTrain, InCols]
part_test <- training[-InTrain,]
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse);library(caret)
library(knitr);library(DT)
model_rpart <- train(classe ~ ., data = part_train, method = "rpart",
trControl = trainControl(method = "cv", number = 3))
confusionMatrix(model_rpart)
model_rpart <- train(classe ~ ., data = part_train, method = "rpart",
number = 3))
model_rpart <- train(classe ~ ., data = part_train, method = "rpart",
number = 3)
model_rpart <- train(classe ~ ., data = part_train, method = "rpart")
confusionMatrix(model_rpart)
## fit the CART model
model_rpart <- train(classe ~ ., data = part_train, method = "rpart")
## cache the fitted model
saveRDS(model_rpart, "./model/model_rpart.rds")
## fit the GBM
model_gbm <- train(classe ~ ., data = part_train, method = "gbm")
## cache the fitted model
saveRDS(model_gbm, "./model/model_gbm.rds")
## fit the rf model
model_rf <- train(classe ~ ., data = part_train, method = "rf")
model_rf <- readRDS("./model_model_rf.rds")
model_rf <- readRDS("./model/model_rf.rds")
## predict the class
predict_rpart <- predict(model_rpart, newdata = part_test)
predict_gbm <- predict(model_gbm, newdata = part_test)
predict_rf <- predict(model_rf, newdata = part_test)
## get the confusion matrix for the models
cfm_rpart <- confusionMatrix(predict_rpart, part_test$classe)
part_test <- training[-InTrain,] %>% mutate(classe = factor(classe))
## get the confusion matrix for the models
cfm_rpart <- confusionMatrix(predict_rpart, part_test$classe)
cfm_gbm <- confusionMatrix(predict_gbm, part_test$classe)
cfm_rf <- confusionMatrix(predict_rf, part_test$classe)
tibble(MODEL = c("CART", "GBM", "RF"),
ACCURACY = rbind(cfm_rpart$overall["Accuracy"],
cfm_gmb$overall["Accuracy"],
cfm_rf$overall["Accuracy"]))
tibble(MODEL = c("CART", "GBM", "RF"),
ACCURACY = rbind(cfm_rpart$overall["Accuracy"],
cfm_gbm$overall["Accuracy"],
cfm_rf$overall["Accuracy"]))
tibble(MODEL = c("CART", "GBM", "RF"),
ACCURACY = c(cfm_rpart$overall["Accuracy"],
cfm_gbm$overall["Accuracy"],
cfm_rf$overall["Accuracy"]))
cfm_rf
model_rf
getTree(model_rf$finalModel)
randomForest::getTree(model_rf$finalModel)
randomForest::getTree(model_rf$finalModel, k = 3)
importance(model_rf)
varImp(model_rf)
?varImp()
varImpPlot(model_rf)
varImpPlot(model_rf)
library(knitr);library(DT);library(randomForest)
varImpPlot(model_rf)
varImp(model_rf)
varImp(model_rf)
## load the downloaded data
test <- read.csv("./data/pml-testing.csv", stringsAsFactors = FALSE,
## attn: several different NA strings
na.strings = c("", "#DIV/0!", NA_character_))
rm(testing_predict)
## make the prediction
predict_quiz <- predict(model_rf, newdata = test)
## the prediction results are the following
cbind(test$problem_id, predict_quiz)
## the prediction results are the following
tibble(PROBLEM_ID = test$problem_id, PREDICTED_VALUE = predict_quiz)
rm(list=ls())
